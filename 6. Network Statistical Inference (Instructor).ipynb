{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy.stats import norm, ks_2samp  # no scipy - comment out\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will walk through a hacker's approach to statistical thinking, as applied to network analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistics in a Nutshell\n",
    "\n",
    "All of statistics can be broken down into two activities:\n",
    "\n",
    "- Descriptively summarizing data. (a.k.a. **\"descriptive statistics\"**)\n",
    "- Figuring out whether something happened by random chance. (a.k.a. **\"inferential statistics\"**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Descriptive Statistics\n",
    "\n",
    "- Centrality measures: mean, median, mode\n",
    "- Variance measures: inter-quartile range (IQR), variance and standard deviation\n",
    "\n",
    "### Inferential Statistics\n",
    "\n",
    "- Models of Randomness (see below)\n",
    "- Hypothesis Testing\n",
    "- Fitting Statistical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Models of Randomness**\n",
    "\n",
    "*Discrete Distributions:*\n",
    "\n",
    "- Bernoulli: probability p of success in 1 try (e.g. one flip of coin).\n",
    "- Binomial: probability p of success given n number of tries. `n * bernoulli trials` follows binomial distribution.\n",
    "- Poisson: processes with a per-unit rate.\n",
    "\n",
    "*Continuous Distributions:*\n",
    "\n",
    "- Uniform: equal probability over the range of probable values. Can also be made discrete.\n",
    "- Normal: everyone's favourite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Playing with Real Data!\n",
    "\n",
    "In this notebook, we will statistically test whether a protein-protein interaction network follows an Erdos-Renyi random graph model or not. We will also see how to load real data into a NetworkX graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Take a quick peek at what the edge list looks like.\n",
    "!head datasets/moreno_propro/out.moreno_propro_propro.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the data.\n",
    "# Note from above that we have to skip the first two rows, and that there's no header column,and that the edges are\n",
    "# delimited by spaces in between the nodes. Hence the syntax below:\n",
    "propro = pd.read_csv('datasets/moreno_propro/out.moreno_propro_propro.txt', skiprows=2, header=None, delimiter=' ')\n",
    "propro.columns = ['prot1_id', 'prot2_id']\n",
    "propro.head()\n",
    "len(propro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Exercise:** Put to work your knowledge of how the `networkx` API works. Add these edges into the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "proproG = nx.Gra ph()\n",
    "proproG.add_edges_from(zip(propro['prot1_id'], propro['prot2_id']))\n",
    "len(proproG.edges()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Exercise:** Compute some basic descriptive statistics about the graph, namely:\n",
    "\n",
    "- the number of nodes,\n",
    "- the number of edges,\n",
    "- the graph density,\n",
    "- the distribution of degree centralities in the graph,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Number of nodes:\n",
    "len(proproG.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Number of edges:\n",
    "len(proproG.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Graph density:\n",
    "# \n",
    "nx.density(proproG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Degree centrality distribution:\n",
    "list(nx.degree_centrality(proproG).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Exercise:** Make a histogram of the degree centralities for the protein-protein interaction graph, and the E-R graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ppG_deg_centralities = list(nx.degree_centrality(proproG).values())\n",
    "n, bins, patches = plt.hist(ppG_deg_centralities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "erG = nx.erdos_renyi_graph(n=len(proproG.nodes()), p=nx.density(proproG))\n",
    "erG_deg_centralities = list(nx.degree_centrality(erG).values())\n",
    "n, bins, patches = plt.hist(erG_deg_centralities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From visualizing these two distributions, it is clear that they look very different. How do we quantify this difference, and statistically test whether the protein-protein graph could have arisen under an Erdos-Renyi model?\n",
    "\n",
    "**Discuss this with your neighbors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One thing we might observe is that the variance, that is the \"spread\" around the mean, differs between the E-R model compared to our data. Therefore, we can compare variance of the data to the distribtion of variances under an E-R model.\n",
    "\n",
    "This is essentially following the logic of statistical inference by 'hacking' (not to be confused with the statistical bad practice of p-hacking)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise:** Fill in the skeleton code below to simulate 100 E-R graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Generate 100 E-R graph degree centrality variance measurements and store them.\n",
    "# Takes ~50 seconds or so.\n",
    "er_vars = np.zeros(100)  # variances for 1000 simulaed E-R graphs.\n",
    "for i in range(100):\n",
    "    erG = nx.erdos_renyi_graph(n=len(proproG.nodes()), p=nx.density(proproG))\n",
    "    erG_deg_centralities = list(nx.degree_centrality(erG).values())\n",
    "    er_vars[i] = np.var(erG_deg_centralities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Compute the test statistic that is going to be used for the hypothesis test.\n",
    "# Hint: numpy has a \"var\" function implemented that computes the variance of a distribution of data.\n",
    "ppG_var = np.var(ppG_deg_centralities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Do a quick visual check\n",
    "n, bins, patches = plt.hist(er_vars)\n",
    "plt.vlines(ppG_var, ymin=0, ymax=max(n), color='red', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Visually, it should be quite evident that the protein-protein graph did not come from an E-R distribution. Statistically, we can also use the hypothesis test procedure to quantitatively test this, using our simulated E-R data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Conduct the hypothesis test.\n",
    "ppG_var > np.percentile(er_vars, 99)  # we can only use the 99th percentile, because there are only 100 data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another way to do this is to use the 2-sample Kolmogorov-Smirnov test implemented in the `scipy.stats` module. From the docs:\n",
    "\n",
    "> This tests whether 2 samples are drawn from the same distribution. Note\n",
    "that, like in the case of the one-sample K-S test, the distribution is\n",
    "assumed to be continuous.\n",
    ">\n",
    "> This is the two-sided test, one-sided tests are not implemented.\n",
    "The test uses the two-sided asymptotic Kolmogorov-Smirnov distribution.\n",
    ">\n",
    "> If the K-S statistic is small or the p-value is high, then we cannot\n",
    "reject the hypothesis that the distributions of the two samples\n",
    "are the same.\n",
    "\n",
    "As an example to convince yourself that this test works, run the synthetic examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Scenario 1: Data come from the same distributions.\n",
    "# Notice the size of the p-value.\n",
    "dist1 = npr.random(size=(100))\n",
    "dist2 = npr.random(size=(100))\n",
    "\n",
    "ks_2samp(dist1, dist2)\n",
    "# dist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Scenario 2: Data come from different distributions. \n",
    "# Note the size of the KS statistic, and the p-value.\n",
    "\n",
    "dist1 = norm(3, 1).rvs(100)\n",
    "dist2 = norm(5, 1).rvs(100)\n",
    "\n",
    "ks_2samp(dist1, dist2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Now, conduct the K-S test for one synthetic graph and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Now try it on the data distribution\n",
    "ks_2samp(erG_deg_centralities, ppG_deg_centralities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Networks may be high-dimensional objects, but the logic for inference on network data essentially follows the same logic as for 'regular' data:\n",
    "\n",
    "- Identify a model of 'randomness' that may model how your data may have been generated.\n",
    "- Compute a \"test statistic\" for your data and the model.\n",
    "- Compute the probability of observing the data's test statistic under the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Further Reading\n",
    "\n",
    "Jake Vanderplas' \"Statistics for Hackers\" slides: https://speakerdeck.com/jakevdp/statistics-for-hackers\n",
    "\n",
    "Allen Downey's \"There is Only One Test\": http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
